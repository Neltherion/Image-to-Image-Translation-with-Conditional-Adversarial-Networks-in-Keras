{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from itertools import izip\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from keras.engine import Input, Model, merge\n",
    "from keras.layers import BatchNormalization, UpSampling2D, Dropout, Flatten, Dense, LeakyReLU, Activation\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "\n",
    "# Read files using a Generator... You have to download your needed Dataset\n",
    "# The available datasets are mentioned in the paper\n",
    "# This function is made to fetch the \"CMP Building Facades\" dataset from your HardDrive\n",
    "def readFilesByGenerator(batchSize=1, targetSize=(256, 256)):\n",
    "    print(\"Reading Images...\")\n",
    "\n",
    "    train_gray_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    train_rgb_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    test_gray_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    test_rgb_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    train_gray_generator = train_gray_datagen.flow_from_directory(\n",
    "        './Data/Train',\n",
    "        batch_size=batchSize,\n",
    "        target_size=targetSize,\n",
    "        color_mode='rgb',\n",
    "        class_mode=None,\n",
    "        shuffle=True,\n",
    "        seed=1,\n",
    "        classes=['Facade'])\n",
    "    train_rgb_generator = train_rgb_datagen.flow_from_directory(\n",
    "        './Data/Train',\n",
    "        batch_size=batchSize,\n",
    "        target_size=targetSize,\n",
    "        color_mode='rgb',\n",
    "        class_mode=None,\n",
    "        shuffle=True,\n",
    "        seed=1,\n",
    "        classes=['Real'])\n",
    "\n",
    "    test_gray_generator = test_gray_datagen.flow_from_directory(\n",
    "        './Data/Test',\n",
    "        batch_size=batchSize,\n",
    "        target_size=targetSize,\n",
    "        color_mode='rgb',\n",
    "        class_mode=None,\n",
    "        shuffle=True,\n",
    "        seed=2,\n",
    "        classes=['Facade'])\n",
    "\n",
    "    test_rgb_generator = test_rgb_datagen.flow_from_directory(\n",
    "        './Data/Test',\n",
    "        batch_size=batchSize,\n",
    "        target_size=targetSize,\n",
    "        color_mode='rgb',\n",
    "        class_mode=None,\n",
    "        shuffle=True,\n",
    "        seed=2,\n",
    "        classes=['Real'])\n",
    "\n",
    "    # Iterate through them using a lazy izip because of Memory constraints\n",
    "    train_generator = izip(train_gray_generator, train_rgb_generator)\n",
    "    test_generator = izip(test_gray_generator, test_rgb_generator)\n",
    "\n",
    "    print(\"Finished Reading Images...\")\n",
    "    return train_generator, test_generator\n",
    "\n",
    "\n",
    "# Create the Generator (This is the U-Net mentioned in the paper)\n",
    "def generator_model():\n",
    "    generator_input = Input(batch_shape=(None, 3, 256, 256), name='generator_input')\n",
    "\n",
    "    # ENCODER\n",
    "    conv1_64 = Convolution2D(64, 4, 4, subsample=(2, 2), border_mode='same', W_regularizer=l2(0.001))(generator_input)\n",
    "    conv1_64 = LeakyReLU(alpha=0.2)(conv1_64)\n",
    "\n",
    "    conv2_128 = Convolution2D(128, 4, 4, subsample=(2, 2), border_mode='same', W_regularizer=l2(0.001))(conv1_64)\n",
    "    conv2_128 = BatchNormalization(axis=1, mode=2)(conv2_128)\n",
    "    conv2_128 = LeakyReLU(alpha=0.2)(conv2_128)\n",
    "\n",
    "    conv3_256 = Convolution2D(256, 4, 4, subsample=(2, 2), border_mode='same', W_regularizer=l2(0.001))(conv2_128)\n",
    "    conv3_256 = BatchNormalization(axis=1, mode=2)(conv3_256)\n",
    "    conv3_256 = LeakyReLU(alpha=0.2)(conv3_256)\n",
    "\n",
    "    conv4_512 = Convolution2D(512, 4, 4, subsample=(2, 2), border_mode='same', W_regularizer=l2(0.001))(conv3_256)\n",
    "    conv4_512 = BatchNormalization(axis=1, mode=2)(conv4_512)\n",
    "    conv4_512 = LeakyReLU(alpha=0.2)(conv4_512)\n",
    "\n",
    "    conv5_512 = Convolution2D(512, 4, 4, subsample=(2, 2), border_mode='same', W_regularizer=l2(0.001))(conv4_512)\n",
    "    conv5_512 = BatchNormalization(axis=1, mode=2)(conv5_512)\n",
    "    conv5_512 = LeakyReLU(alpha=0.2)(conv5_512)\n",
    "\n",
    "    conv6_512 = Convolution2D(512, 4, 4, subsample=(2, 2), border_mode='same', W_regularizer=l2(0.001))(conv5_512)\n",
    "    conv6_512 = BatchNormalization(axis=1, mode=2)(conv6_512)\n",
    "    conv6_512 = LeakyReLU(alpha=0.2)(conv6_512)\n",
    "\n",
    "    conv7_512 = Convolution2D(512, 4, 4, subsample=(2, 2), border_mode='same', W_regularizer=l2(0.001))(conv6_512)\n",
    "    conv7_512 = BatchNormalization(axis=1, mode=2)(conv7_512)\n",
    "    conv7_512 = LeakyReLU(alpha=0.2)(conv7_512)\n",
    "\n",
    "    conv8_512 = Convolution2D(512, 4, 4, subsample=(2, 2), border_mode='same', W_regularizer=l2(0.001))(conv7_512)\n",
    "    conv8_512 = BatchNormalization(axis=1, mode=2)(conv8_512)\n",
    "    conv8_512 = LeakyReLU(alpha=0.2)(conv8_512)\n",
    "\n",
    "    # DECODER\n",
    "    conv9_512 = UpSampling2D()(conv8_512)\n",
    "    conv9_512 = Convolution2D(512, 4, 4, border_mode='same', W_regularizer=l2(0.001))(conv9_512)\n",
    "    conv9_512 = BatchNormalization(axis=1, mode=2)(conv9_512)\n",
    "    conv9_512 = Dropout(0.5)(conv9_512)\n",
    "    conv9_512 = Activation('relu')(conv9_512)\n",
    "    merge_2_2 = merge((conv9_512, conv7_512), mode='concat', concat_axis=1)\n",
    "\n",
    "    conv10_512 = UpSampling2D()(merge_2_2)\n",
    "    conv10_512 = Convolution2D(512, 4, 4, border_mode='same', W_regularizer=l2(0.001))(conv10_512)\n",
    "    conv10_512 = BatchNormalization(axis=1, mode=2)(conv10_512)\n",
    "    conv10_512 = Dropout(0.5)(conv10_512)\n",
    "    conv10_512 = Activation('relu')(conv10_512)\n",
    "    merge_4_4 = merge((conv10_512, conv6_512), mode='concat', concat_axis=1)\n",
    "\n",
    "    conv11_512 = UpSampling2D()(merge_4_4)\n",
    "    conv11_512 = Convolution2D(512, 4, 4, border_mode='same', W_regularizer=l2(0.001))(conv11_512)\n",
    "    conv11_512 = BatchNormalization(axis=1, mode=2)(conv11_512)\n",
    "    conv11_512 = Dropout(0.5)(conv11_512)\n",
    "    conv11_512 = Activation('relu')(conv11_512)\n",
    "    merge_8_8 = merge((conv11_512, conv5_512), mode='concat', concat_axis=1)\n",
    "\n",
    "    conv12_512 = UpSampling2D()(merge_8_8)\n",
    "    conv12_512 = Convolution2D(512, 4, 4, border_mode='same', W_regularizer=l2(0.001))(conv12_512)\n",
    "    conv12_512 = BatchNormalization(axis=1, mode=2)(conv12_512)\n",
    "    conv12_512 = Activation('relu')(conv12_512)\n",
    "    merge_16_16 = merge((conv12_512, conv4_512), mode='concat', concat_axis=1)\n",
    "\n",
    "    conv13_512 = UpSampling2D()(merge_16_16)\n",
    "    conv13_512 = Convolution2D(512, 4, 4, border_mode='same', W_regularizer=l2(0.001))(conv13_512)\n",
    "    conv13_512 = BatchNormalization(axis=1, mode=2)(conv13_512)\n",
    "    conv13_512 = Activation('relu')(conv13_512)\n",
    "    merge_32_32 = merge((conv13_512, conv3_256), mode='concat', concat_axis=1)\n",
    "\n",
    "    conv14_256 = UpSampling2D()(merge_32_32)\n",
    "    conv14_256 = Convolution2D(512, 4, 4, border_mode='same', W_regularizer=l2(0.001))(conv14_256)\n",
    "    conv14_256 = BatchNormalization(axis=1, mode=2)(conv14_256)\n",
    "    conv14_256 = Activation('relu')(conv14_256)\n",
    "    merge_64_64 = merge((conv14_256, conv2_128), mode='concat', concat_axis=1)\n",
    "\n",
    "    conv15_128 = UpSampling2D()(merge_64_64)\n",
    "    conv15_128 = Convolution2D(256, 4, 4, border_mode='same', W_regularizer=l2(0.001))(conv15_128)\n",
    "    conv15_128 = BatchNormalization(axis=1, mode=2)(conv15_128)\n",
    "    conv15_128 = Activation('relu')(conv15_128)\n",
    "    merge_128_128 = merge((conv15_128, conv1_64), mode='concat', concat_axis=1)\n",
    "\n",
    "    conv16_64 = UpSampling2D()(merge_128_128)\n",
    "    conv16_64 = Convolution2D(128, 4, 4, border_mode='same', W_regularizer=l2(0.001))(conv16_64)\n",
    "    conv16_64 = BatchNormalization(axis=1, mode=2)(conv16_64)\n",
    "    conv16_64 = Activation('relu')(conv16_64)\n",
    "    merge_256_256 = merge((conv16_64, generator_input), mode='concat', concat_axis=1)\n",
    "\n",
    "    generator_output = Convolution2D(3, 4, 4, activation='sigmoid', border_mode='same', name='generator_output')(merge_256_256)\n",
    "\n",
    "    model = Model(input=generator_input, output=generator_output)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create the Discriminator (This is the 70x70 Receptive Field Discriminator mentioned in the paper)\n",
    "def discriminator_model():\n",
    "    discriminator_input = Input(batch_shape=(None, 3, 256, 256))\n",
    "\n",
    "    conv1_64 = Convolution2D(64, 4, 4, subsample=(2, 2), W_regularizer=l2(0.001))(discriminator_input)\n",
    "    conv1_64 = LeakyReLU(alpha=0.2)(conv1_64)\n",
    "\n",
    "    conv2_128 = Convolution2D(128, 4, 4, subsample=(2, 2), W_regularizer=l2(0.001))(conv1_64)\n",
    "    conv2_128 = BatchNormalization(axis=1, mode=2)(conv2_128)\n",
    "    conv2_128 = LeakyReLU(alpha=0.2)(conv2_128)\n",
    "\n",
    "    conv3_256 = Convolution2D(256, 4, 4, subsample=(2, 2), W_regularizer=l2(0.001))(conv2_128)\n",
    "    conv3_256 = BatchNormalization(axis=1, mode=2)(conv3_256)\n",
    "    conv3_256 = LeakyReLU(alpha=0.2)(conv3_256)\n",
    "\n",
    "    conv4_512 = Convolution2D(512, 4, 4, subsample=(2, 2), W_regularizer=l2(0.001))(conv3_256)\n",
    "    conv4_512 = BatchNormalization(axis=1, mode=2)(conv4_512)\n",
    "    conv4_512 = LeakyReLU(alpha=0.2)(conv4_512)\n",
    "\n",
    "    # conv5_512 = Convolution2D(512, 4, 4, subsample=(2, 2), W_regularizer=l2(0.001))(conv4_512)\n",
    "    # conv5_512 = BatchNormalization(axis=1, mode=2)(conv5_512)\n",
    "    # conv5_512 = LeakyReLU(alpha=0.2)(conv5_512)\n",
    "    #\n",
    "    # conv6_512 = Convolution2D(512, 4, 4, subsample=(2, 2), W_regularizer=l2(0.001))(conv5_512)\n",
    "    # conv6_512 = BatchNormalization(axis=1, mode=2)(conv6_512)\n",
    "    # conv6_512 = LeakyReLU(alpha=0.2)(conv6_512)\n",
    "\n",
    "    flatten = Flatten()(conv4_512)\n",
    "    discriminator_output = Dense(1, activation='sigmoid')(flatten)\n",
    "\n",
    "    model = Model(input=discriminator_input, output=[discriminator_output, discriminator_input])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Concat the two Networks and make the cGAN network\n",
    "def generator_to_discriminator_model(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    generator_to_discriminator = Model(input=generator.input, output=discriminator(generator.output))\n",
    "\n",
    "    return generator_to_discriminator\n",
    "\n",
    "\n",
    "generator = generator_model()\n",
    "# generator.load_weights('./Model/Archive/FinalizedModels/Facades/GeneratorWeights-Index1000')\n",
    "\n",
    "discriminator = discriminator_model()\n",
    "# discriminator.load_weights('./Model/Archive/FinalizedModels/Facades/DiscriminatorWeights-Index1000')\n",
    "\n",
    "# Only train the Discriminator on the binary_crossentropy loss as the L1 loss isn't needed here\n",
    "discriminator.compile(loss=['binary_crossentropy', 'mae'], loss_weights=[1., 0], optimizer=Adam(lr=0.00005, beta_1=0.5))\n",
    "\n",
    "generator_to_discriminator = generator_to_discriminator_model(generator, discriminator)\n",
    "\n",
    "# Train the cGAN with 2 losses, the binary_crossentropy loss counts for GAN and the L1 MAE loss has a weight of 100\n",
    "generator_to_discriminator.compile(loss=['binary_crossentropy', 'mae'], loss_weights=[1., 100.], optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "IMAGE_COUNT = 400\n",
    "train_generator, test_generator = readFilesByGenerator(batchSize=BATCH_SIZE, targetSize=(256, 256))\n",
    "\n",
    "d_loss_log = []\n",
    "g_loss_log = []\n",
    "\n",
    "for index, (train_data, test_data) in enumerate(izip(train_generator, test_generator)):\n",
    "    X_train_gray = train_data[0]\n",
    "    X_train_rgb = train_data[1]\n",
    "    X_test_gray = test_data[0]\n",
    "    X_test_rgb = test_data[1]\n",
    "\n",
    "    # only run this once in the first epoch\n",
    "    if index == 0:\n",
    "        generated_train_images = generator.predict(X_train_gray)\n",
    "        generated_test_images = generator.predict(X_test_gray)\n",
    "\n",
    "    # Train the discriminator on real and fake data\n",
    "    y = [1] * BATCH_SIZE\n",
    "    d_loss_real = discriminator.train_on_batch(X_train_rgb, [np.array(y), X_train_rgb])[1]\n",
    "    y = [0] * BATCH_SIZE\n",
    "    d_loss_fake = discriminator.train_on_batch(generated_train_images, [np.array(y), X_train_rgb])[1]\n",
    "    d_loss = (d_loss_real + d_loss_fake) / 2.0\n",
    "    d_loss_log.append(d_loss)\n",
    "\n",
    "    # Train the cGAN network on fake data\n",
    "    discriminator.trainable = False\n",
    "    g_loss = generator_to_discriminator.train_on_batch(X_train_gray, [np.array([1] * BATCH_SIZE), X_train_rgb])[1]\n",
    "    g_loss_log.append(g_loss)\n",
    "    discriminator.trainable = True\n",
    "\n",
    "    # Generate images to plot and show\n",
    "    generated_train_images = generator.predict(X_train_gray)\n",
    "    generated_test_images = generator.predict(X_test_gray)\n",
    "    test_accuracy = discriminator.predict(generated_test_images)[0]\n",
    "    if index % 50 == 0 or (0.9 <= test_accuracy):\n",
    "        print(\"Index %d D-Loss %.3f DG-Loss %.3f\" % (index, d_loss, g_loss))\n",
    "\n",
    "        fig = plt.figure(figsize=(50, 20))\n",
    "        for imageIndex, image in enumerate(generated_test_images):\n",
    "            ax = fig.add_subplot(3, len(generated_test_images), imageIndex + 1)\n",
    "            ax.imshow(X_test_rgb[imageIndex].transpose(1, 2, 0))\n",
    "            ax.axis(\"off\")\n",
    "            ax = fig.add_subplot(3, len(generated_test_images), len(generated_test_images) + imageIndex + 1)\n",
    "            ax.imshow(X_test_gray[imageIndex].transpose(1, 2, 0))\n",
    "            ax.axis(\"off\")\n",
    "            ax = fig.add_subplot(3, len(generated_test_images), len(generated_test_images) * 2 + imageIndex + 1)\n",
    "            ax.imshow(generated_test_images[imageIndex].transpose(1, 2, 0))\n",
    "            ax.axis(\"off\")\n",
    "        plt.subplots_adjust(bottom=0.6, wspace=0.05, hspace=0)\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(\"./Model/Images/Index %d Accuracy %.3f.png\" % (index, test_accuracy))\n",
    "        print(\"Index %d Accuracy %.3f\" % (index, test_accuracy))\n",
    "        if 0.9 <= test_accuracy:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        plt.plot(d_loss_log, color='blue', label='D-Loss Total')\n",
    "        plt.plot(g_loss_log, color='red', label='DG-Loss', alpha=0.75)\n",
    "        plt.legend(loc='best')\n",
    "        plt.ylim((0, 3))\n",
    "\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    # Save the weights\n",
    "    if (index != 0) and (index % 1000 == 0):\n",
    "        generator.save_weights('./Model/Images/Models/GeneratorWeights-Index%s' % index, True)\n",
    "        discriminator.save_weights('./Model/Images/Models/DiscriminatorWeights-Index%s' % index, True)\n",
    "        print(\"Models Saved => Index %s\" % index)\n",
    "\n",
    "    # Clear the output as it tends to get crowded!\n",
    "    if index != 0 and index % 1000 == 0:\n",
    "        clear_output()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}